#### [AF-SEG：通过自我监督和生成对抗网络进行图像分割的无注释方法](https://ieeexplore.ieee.org/document/9098535/references#references)

 [2020年IEEE第17届国际生物医学成像国际研讨会（ISBI）](https://ieeexplore.ieee.org/xpl/conhome/9091448/proceeding)

我们这篇文章介绍了一种无注释分割的方法，他是在2019年提出的SC-GAN的基础上提出的。

##### [SC-GAN](https://link.springer.com/chapter/10.1007/978-3-030-32245-8_79)

##### 通过视网膜图像中的知识转移进行无注释的心脏血管分割【 MICCAI 2019]

在冠状动脉分割任务中，图像的前景和背景完全不匹配，因此设计了SC-GAN允许生成器和鉴别器分别生成图像前景和图像背景，然后将它们组合起来以更有效地训练分割模型，完成两个不同解剖区域之间的知识转移。

###### SC-GAN的结构

训练过程中，同时训练生成器、鉴别器和分段器。

测试过程中，只需要经过训练的分段器就可以对冠状动脉进行分段，需要的空间和时间比训练少。

![image-20200823210718091](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823210718091.png)

###### 生成器

使用的是U-Net网络，输入是眼底图像(RealA)的平均值和它的DSA图像(RealB)的平均值，输出(FakeB)与输入的尺寸相同。为了确保FakeB有视网膜血管和冠状动脉，使用人工注释视网膜血管和Frangi分割DSA图像来提取FakeB中的两个血管区域(Part A和Part B),然后使用形状一致的损失进行正则化使FakeB中区域的内容与原始图像中相应的区域一致。

如下为损失函数，A表示眼底图像，B表示DSA图像，labelA和labelB分别是视网膜血管注释和Frangi分割结果![image-20200823223825884](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823223825884.png)

###### 鉴别器

我们期望FakeB的背景与DSA图像的背景足够相似，所以首先使用注释和Frangi DSA分析结果得到血管区域，在生成的和真实的DSA图像中充当背景

![image-20200823213919991](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823213919991.png)

其中B∗(图1中的真实B∗)表示在注入对比介质之前随机选择的DSA图像，这保证了背景无血管。采用PatchGAN作为鉴别器的结构。生成器与鉴别器之间的对抗性损失可以表示为

![image-20200823214450144](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823214450144.png)

###### 分割器

主要结构也是U-Net。 使用Multi Label Soft Margin Loss作为分割器的目标函数：![image-20200823214617163](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823214617163.png)

最终的目标函数如下

![image-20200823221308720](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823221308720.png)

尽管SC-GAN实现了无注释的冠状动脉分割，但它有两个主要限制。首先，SC-GAN需要一个辅助标记的数据集（眼底图像）作为知识转移过程中的源域数据。其次，要训练分割模型，它需要将数据与其他具有清晰背景的图像合成，而这些背景通常很难获得。

##### AF-SEG

受SC-GAN的启发，提出了一个更通用的无注释分割框架AF-SEG，该框架不需要任何标记数据或其他干净的背景图像，称为AF-SEG。

首先执行传统的无注释方法以获得粗略的分割。然后使用GAN合成与粗略分割相对应的背景图像。最后，使用粗略分割作为合成图像的像素级注释，并监督训练高质量分割模型。在SC-GAN的启发下，分别生成合成图像的前景和背景，然后将两者融合，以确保图像的前景与粗分割相一致。

###### 粗分割：使用传统的无注释方法生成粗略的分割结果

在细胞分割中，采用经典的水平集方法。在血管分割中，采用Hessian分析。在此步骤中获得的粗略分割将用作后续监督学习的注释。

###### 背景生成：生成干净的背景图像以进行最终合成

遵循深度图像优先（DIP）的思想，提出了一种称为深度分割优先（DSP）的新策略，输入图像为原始图像，标签为相应的粗略分割。DSP认为，该模型将在训练过程的早期阶段检测出所有类似标签的结构。因此在培训期间应用了提前停止策略。培训的停止时间由一个超参数A决定，A代表希望最终预测为粗略分割的大小的倍数。在此实验中设置A =2。使用DSP的结果掩盖背景中的假阴性。最后，我们使用诸如DIP类的图像修复技术来生成干净的（无对象）背景图像。

![å¾2-èæ¯çææ¹æ³çå¾ç¤ºã æä»¬çæ¹æ³äº§ççèçï¼ç»¿è²ååï¼è¾å¤§ï¼ä»¥æ©çæ´ä¸ªåé´æ§ã](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/9091448/9098313/9098535/0153-fig-2-source-small.gif)

###### 对应的图像合成与分割

<img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/9091448/9098313/9098535/0153-fig-3-source-small.gif" alt="Fig. 3. - The illustration of corresponding image synthesis and segmentation method." style="zoom:80%;" />

1.生成器（G）：使用U-Net作为其网络主干，其输入是原始图像（Real），输出是合成图像（Fake）。我们引入形状一致损失（L1损失），以确保输入和输出在粗分割中保持一致。![image-20200823224729223](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823224729223.png)

2.鉴别器（D）：确保合成图像在粗分割（weak）之外可以具有干净的背景。首先，我们使用粗略分割来获取生成的合成图像（Fake）的背景区域和干净背景图像（Real *）。![image-20200823224757101](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823224757101.png)

通过对抗训练，鉴别器将在伪造的背景下移除可能的物体。对抗性损失函数如下：![image-20200823224857981](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823224857981.png)

3.分割使用传统的U-net函数，其目标函数为：![image-20200823225030057](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823225030057.png)

因此最终的目标函数为：

![image-20200823225010211](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823225010211.png)

##### 实验结果

背景合成结果：![image-20200823222957514](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823222957514.png)

图像合成结果：![image-20200823223048982](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823223048982.png)

图像分割结果：

![image-20200823223135030](C:\Users\16018\AppData\Roaming\Typora\typora-user-images\image-20200823223135030.png)

结果分析：

本文提出了一种无注释的分割方法，提高了传统分割方法的分割精度。综合图像和粗略分割能够更好地训练分割模型。尽管它不需要人工标记并且可以满足广泛的医学定量分析要求，但还是有局限性的。例如，图片细节不够精准。
